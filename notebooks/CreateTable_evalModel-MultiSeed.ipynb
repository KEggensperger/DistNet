{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Table to summarize results\n",
    "\n",
    "This notebook creates a table with the normalized NLLHs for different models. It expects to find pickled predictions for 10 folds with the following filenames:\n",
    "\n",
    " * ```<scenario_name>.floc.<dist_name>.<fold>.100.<model>.pkl```\n",
    "\n",
    "`eval_model.py` automatically creates such files. \n",
    "\n",
    "**NOTE:** The first cell contains some variables that need to be adjusted. Evaluating all scenarios might take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import scipy.stats as scst\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tabulate\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from helper import load_data, preprocess, data_source_release\n",
    "\n",
    "mean_exp = [\"rf\", \"nn\"]\n",
    "sc_dict = data_source_release.get_sc_dict()\n",
    "\n",
    "# 1) Select the distribution you want to fit\n",
    "floc_exp = [\"lognormal_distfit\", \"lognormal_distfit.rf2\", \"lognormal_distfit.rf\", \"lognormal_nn\"]\n",
    "distribution_hndl = scst.distributions.lognorm\n",
    "#floc_exp = [\"expon_distfit\", \"expon_distfit.rf2\", \"expon_distfit.rf\", \"expon_nn\"]\n",
    "#distribution_hndl = scst.distributions.expon\n",
    "#floc_exp = [\"invgauss_distfit\", \"invgauss_distfit.rf2\", \"invgauss_distfit.rf\", \"invgauss_nn\"]\n",
    "#distribution_hndl = scst.distributions.invgauss\n",
    "\n",
    "# 2) Change the following to existing paths\n",
    "output_dir = \"../\"\n",
    "save_dir = \"../results/\"\n",
    "\n",
    "# 3) Select whethe to compute results for all scenarios or just a single scenario\n",
    "SCENARIOS = []\n",
    "#SCENARIOS = ['clasp_factoring', ]\n",
    "#SCENARIOS = ['saps-CVVAR', ]\n",
    "#SCENARIOS = ['lpg-zeno', ]\n",
    "#SCENARIOS = ['yalsat_qcp', ]\n",
    "#SCENARIOS = ['spear_qcp', ]\n",
    "#SCENARIOS = ['spear_smallworlds', ]\n",
    "#SCENARIOS = ['yalsat_smallworlds', ]\n",
    "\n",
    "load = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_dict = dict()\n",
    "for fl in os.listdir(output_dir):\n",
    "    if not \".100.\" in fl:\n",
    "        # Select only one seed\n",
    "        continue\n",
    "    print(fl, output_dir)\n",
    "\n",
    "    fl_path = os.path.join(output_dir, fl)\n",
    "    \n",
    "    if os.path.isdir(fl_path):\n",
    "        continue\n",
    "    \n",
    "    if not \"pkl\" in fl_path:\n",
    "        continue\n",
    "    \n",
    "    if \"txt\" in fl_path or \"png\" in fl_path:\n",
    "        continue\n",
    "\n",
    "    if not os.path.isfile(fl_path):\n",
    "        fl_path = os.path.join(output_dir)\n",
    "\n",
    "    with open(fl_path, \"rb\") as fh:\n",
    "        pkl = pickle.load(fh)\n",
    "        train_pred = np.array(pkl[0])\n",
    "        val_pred = np.array(pkl[1])\n",
    "        add_info = pkl[2]\n",
    "        task = add_info[\"task\"]\n",
    "        model = add_info[\"model\"]\n",
    "        scenario = add_info[\"scenario\"]\n",
    "        fold = add_info[\"fold\"]\n",
    "\n",
    "        if \"nn\" in add_info[\"model\"] and add_info[\"task\"] == \"floc\":\n",
    "            print(\"%20s\" % scenario, model, fold, add_info[\"loaded\"])\n",
    "    if scenario not in res_dict:\n",
    "        res_dict[scenario] = dict()\n",
    "\n",
    "    if model not in floc_exp and model not in mean_exp:\n",
    "        continue\n",
    "\n",
    "    if task not in res_dict[scenario]:\n",
    "        res_dict[scenario][task] = dict()\n",
    "        \n",
    "    if model not in res_dict[scenario][task]:\n",
    "        res_dict[scenario][task][model] = dict()\n",
    "\n",
    "    res_dict[scenario][task][model][fold] = (train_pred, val_pred)\n",
    "\n",
    "if len(SCENARIOS) == 0:\n",
    "    SCENARIOS = list(res_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for scen in sorted(SCENARIOS):\n",
    "    print(\"### %s\" % scen)\n",
    "    try:\n",
    "        for model in sorted(res_dict[scen][\"mean\"]):\n",
    "            print(\"mean %20s\" % model, len(res_dict[scen][\"mean\"][model]))\n",
    "    except:\n",
    "        pass\n",
    "    for model in sorted(res_dict[scen][\"floc\"]):\n",
    "        print(\"floc %20s\" % model, len(res_dict[scen][\"floc\"][model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nllh_dict = dict()\n",
    "mean_dict = dict()\n",
    "var_dict = dict()\n",
    "if load:\n",
    "    with open(save_dir + \"/\" + distribution_hndl.name + \".nllh.pkl\", \"rb\") as fh:\n",
    "        nllh_dict = pickle.load(fh)\n",
    "        \n",
    "    with open(save_dir + \"/\" + distribution_hndl.name + \".mean.pkl\", \"rb\") as fh:\n",
    "        mean_dict = pickle.load(fh)\n",
    "        \n",
    "    with open(save_dir + \"/\" + distribution_hndl.name + \".var.pkl\", \"rb\") as fh:\n",
    "        var_dict = pickle.load(fh)\n",
    "    print(\"LOADED\")\n",
    "else:\n",
    "    for scen in SCENARIOS:\n",
    "        print(\"##### %s #####\" % scen)\n",
    "        nllh_dict[scen] = dict()\n",
    "        mean_dict[scen] = {\"true\": {\"train\": [], \"val\": []}, \"floc\": dict(), \"mean\": dict()}\n",
    "        var_dict[scen] = {\"true\": {\"train\": [], \"val\": []}, \"floc\": dict(), \"mean\": dict()}\n",
    "\n",
    "        # 1) Load data\n",
    "        sc_dict = data_source_release.get_sc_dict()\n",
    "        data_dir = data_source_release.get_data_dir()\n",
    "\n",
    "        runtimes, features, sat_ls = load_data.\\\n",
    "            get_data(scenario=scen, data_dir=data_dir,\n",
    "                     sc_dict=sc_dict, retrieve=sc_dict[scen]['use'])\n",
    "\n",
    "        # We do not need any features\n",
    "        del features\n",
    "\n",
    "        # Get CV splits\n",
    "        idx = list(range(runtimes.shape[0]))\n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "        fold = -1\n",
    "        for train, valid in kf.split(idx):\n",
    "            fold += 1\n",
    "            #print(\"## Split %d\" % ctr)\n",
    "\n",
    "            y_tra_run = runtimes[train]\n",
    "            y_val_run = runtimes[valid]\n",
    "\n",
    "            y_max_ = np.max(y_tra_run)\n",
    "            y_min_ = 0\n",
    "            y_tra_run = (y_tra_run - y_min_) / y_max_\n",
    "            y_val_run = (y_val_run - y_min_) / y_max_\n",
    "\n",
    "            task = \"floc\"\n",
    "            for model in floc_exp:\n",
    "                if model not in res_dict[scen][task]:\n",
    "                    continue\n",
    "\n",
    "                if model not in nllh_dict[scen]:\n",
    "                    nllh_dict[scen][model] = np.zeros([10, 2]) * np.nan\n",
    "                    mean_dict[scen][task][model] = {\"train\": list(), \"val\": list()}\n",
    "                    var_dict[scen][task][model] = {\"train\": list(), \"val\": list()}\n",
    "\n",
    "                if fold not in res_dict[scen][task][model]:\n",
    "                    print(\"FAILED, %s, %s, %s, fold %d\" % (scen, task, model, fold))\n",
    "                    continue\n",
    "\n",
    "                for observations, data, idx in ([y_tra_run, \"train\", 0], [y_val_run, \"val\", 1]):\n",
    "                    assert observations.shape[0] == res_dict[scen][task][model][fold][idx].shape[0]\n",
    "                    nllh = list()\n",
    "                    mean = list()\n",
    "                    var = list()\n",
    "                    for obs, p in zip(observations, res_dict[scen][task][model][fold][idx]):\n",
    "                        if distribution_hndl.name == \"expon\":\n",
    "                            if type(p) == np.float64: \n",
    "                                p = [p, ]\n",
    "                            if len(p) == 1: p = [0, p[0]]\n",
    "                            assert p[0] == 0\n",
    "                        else:\n",
    "                            if len(p) == 2: p = [p[0], 0, p[1]]\n",
    "                            assert p[1] == 0\n",
    "                        nllh_per_inst = distribution_hndl.logpdf(obs, *p[:-2], loc=p[-2], scale=p[-1]) + np.log(max(obs))              \n",
    "                        nllh_per_inst = np.mean(-nllh_per_inst)\n",
    "                        nllh.append(nllh_per_inst)\n",
    "                        mean.append(distribution_hndl.mean(*p[:-2], loc=p[-2], scale=p[-1]))\n",
    "                        var.append(distribution_hndl.var(*p[:-2], loc=p[-2], scale=p[-1]))\n",
    "                    nllh_dict[scen][model][fold, idx] = np.mean(nllh)\n",
    "                    mean_dict[scen][task][model][data].append(mean)\n",
    "                    var_dict[scen][task][model][data].append(var)\n",
    "\n",
    "            task = \"mean\"\n",
    "            if task not in res_dict[scen]:\n",
    "                continue\n",
    "            for model in mean_exp:\n",
    "                if model not in res_dict[scen][task]:\n",
    "                    continue\n",
    "                if model not in mean_dict[scen][task]:\n",
    "                    mean_dict[scen][task][model] = {\"train\": list(), \"val\": list()}\n",
    "                    var_dict[scen][task][model] = {\"train\": list(), \"val\": list()}\n",
    "                if fold not in res_dict[scen][task][model]:\n",
    "                    print(\"FAILED, %s, %s, %s, fold %d\" % (scen, task, model, fold))\n",
    "                    continue\n",
    "\n",
    "                for observations, data, idx in ([y_tra_run, \"train\", 0], [y_val_run, \"val\", 1]):\n",
    "                    assert observations.shape[0] == len(res_dict[scen][task][model][fold][idx]), (model, scenario, y_tra_run.shape[0], len(res_dict[scen][task][model][fold][idx]))\n",
    "                    mean_ls = list()\n",
    "                    tr_mean = list()\n",
    "                    tr_var = list()\n",
    "                    for obs, mean in zip(observations, res_dict[scen][task][model][fold][idx]):\n",
    "                        mean_ls.append(mean)\n",
    "                        tr_mean.append(np.mean(obs))\n",
    "                        tr_var.append(np.var(obs, ddof=1))\n",
    "\n",
    "                    mean_dict[scen][task][model][data].append(mean_ls)\n",
    "                    if len(mean_dict[scen][\"true\"][data]) == fold:\n",
    "                        mean_dict[scen][\"true\"][data].append(tr_mean)\n",
    "                        var_dict[scen][\"true\"][data].append(tr_var)\n",
    "    with open(save_dir + \"/\" + distribution_hndl.name + \".nllh.pkl\", \"wb\") as fh:\n",
    "        pickle.dump(nllh_dict, fh)\n",
    "\n",
    "    with open(save_dir + \"/\" + distribution_hndl.name + \".mean.pkl\", \"wb\") as fh:\n",
    "        pickle.dump(mean_dict, fh)\n",
    "\n",
    "    with open(save_dir + \"/\" + distribution_hndl.name + \".var.pkl\", \"wb\") as fh:\n",
    "        pickle.dump(var_dict, fh)\n",
    "    print(\"dumped to \" + output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate NLLH table\n",
    "\n",
    "# nan means there are some folds missing\n",
    "# inf means there was no results file found\n",
    "tab_data = list()\n",
    "header = [\"sc\"] + floc_exp\n",
    "for scen in sorted(nllh_dict.keys()):\n",
    "    dummy_array = np.ones([2, 2]) * np.inf\n",
    "    tab_data.append([scen] + [np.mean(nllh_dict[scen].get(m, dummy_array)[:, 0]) for m in header[1:]])\n",
    "    tab_data.append([\"\", ] + [np.mean(nllh_dict[scen].get(m, dummy_array)[:, 1]) for m in header[1:]])\n",
    "\n",
    "a = tabulate.tabulate(tab_data, headers=header, floatfmt=\"5.3f\")\n",
    "print(a)\n",
    "\n",
    "with open(\"%s/nllh_%s.txt\" % (save_dir, distribution_hndl.name), \"w\") as fh:\n",
    "    fh.write(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
