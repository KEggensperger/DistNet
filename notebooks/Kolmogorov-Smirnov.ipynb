{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import itertools\n",
    "import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import functools\n",
    "import tabulate\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from helper import load_data, preprocess, data_source_release, dist_helper\n",
    "\n",
    "sc_dict = data_source_release.get_sc_dict()\n",
    "data_dir = data_source_release.get_data_dir()\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-deep')\n",
    "dpi=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCENARIOS = [\"yalsat_swgcp\", \"spear_swgcp\",\n",
    "             \"clasp_factoring\", \"saps-CVVAR\",\n",
    "             \"lpg-zeno\", \"yalsat_qcp\", \"spear_qcp\"\n",
    "            ]\n",
    "DISTS = [\"invgauss_floc\", \"norm\", \"lognorm_floc\", \"expon_floc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "p_dict = dict()\n",
    "lkh_dict = dict()\n",
    "param_dict = dict()\n",
    "\n",
    "for SC in SCENARIOS:\n",
    "    p_dict[SC] = dict()\n",
    "    lkh_dict[SC] = dict()\n",
    "    param_dict[SC] = dict()\n",
    "    print(\"Load %s\" % SC)\n",
    "    \n",
    "    runtimes, _, _ = load_data.get_data(scenario=SC, data_dir=data_dir, \n",
    "                                        sc_dict=sc_dict, retrieve=sc_dict[SC]['use'])\n",
    "\n",
    "    print(runtimes.shape)\n",
    "    y_max_ = np.max(np.max(runtimes))\n",
    "    print(y_max_)\n",
    "    runtimes = (runtimes) / y_max_\n",
    "    \n",
    "    for dist_name in DISTS:\n",
    "        #if \"floc\" in dist_name:\n",
    "        #    continue\n",
    "        start = time.time()\n",
    "        print(\"{:>20s}\".format(dist_name), end=\"\")\n",
    "        p_dict[SC][dist_name] = list()\n",
    "        lkh_dict[SC][dist_name] = list()\n",
    "        param_dict[SC][dist_name] = list()\n",
    "\n",
    "        for idx, instance in enumerate(runtimes):\n",
    "            assert len(instance) == 100\n",
    "            if idx%int(len(runtimes)/10) == 0: print(\".\",end=\"\")\n",
    "            instance = np.array(instance)\n",
    "            param = dist_helper.fit_dist(x=instance, dist_name=dist_name)\n",
    "            param_dict[SC][dist_name].append(param)\n",
    "            \n",
    "            p = dist_helper.kstest(x=instance, dist_name=dist_name, param=param)\n",
    "            lkh = dist_helper.nllh(instance, param, dist_name)\n",
    "\n",
    "            p_dict[SC][dist_name].append(p)\n",
    "            lkh_dict[SC][dist_name].append(lkh)\n",
    "        dur = time.time() - start\n",
    "        print(\"%3.2gsec len: %3.2g mean_p: %3.2g, mean lkh: %3.2g\" % (dur, len(runtimes), np.mean(p_dict[SC][dist_name]), np.mean(lkh_dict[SC][dist_name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_trans = {\n",
    "\"expon_floc\": \"EXP\",\n",
    "\"invgauss_floc\": \"INV\",\n",
    "\"lognorm_floc\": \"LOG\",\n",
    "\"norm\": \"N\",\n",
    "}\n",
    "tabular_data = list()\n",
    "\n",
    "for SC in SCENARIOS:\n",
    "\n",
    "    keys = sorted(DISTS)\n",
    "\n",
    "    perc_ls = list()\n",
    "    mean_ls = list()\n",
    "    l_ls = list()\n",
    "    d_ls = list()\n",
    "    for dist_name in keys:\n",
    "        #if \"floc\" in dist_name:\n",
    "        #    continue\n",
    "        num_instances = len(p_dict[SC][dist_name])\n",
    "        num_equal = np.mean([1 if p <= 0.01 else 0 for p in p_dict[SC][dist_name]])*100\n",
    "        perc_ls.append(num_equal)\n",
    "        l_ls.append(np.mean(lkh_dict[SC][dist_name]))\n",
    "        d_ls.append(dist_trans[dist_name])\n",
    "\n",
    "    sort_idx = np.argsort(l_ls)\n",
    "    \n",
    "    TOP = len(DISTS)\n",
    "    tabular_data.append([SC, ])\n",
    "    tabular_data[-1].extend([d_ls[i] for i in sort_idx[:TOP]])\n",
    "    tabular_data[-1].extend([d_ls[i] for i in sort_idx[:TOP]])\n",
    "    tabular_data.append([\" \", ])\n",
    "    tabular_data[-1].extend([round(l_ls[i], 3) for i in sort_idx[:TOP]])\n",
    "    tabular_data[-1].extend([round(perc_ls[i],1) for i in sort_idx[:TOP]])\n",
    "\n",
    "a = tabulate.tabulate(tabular_data, tablefmt=\"latex\", floatfmt=\"7.4\")\n",
    "print(a)\n",
    "#with open(\"results/Kolmo_res.tex\", \"w\") as fh:\n",
    "#    fh.write(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for SC in SCENARIOS:\n",
    "    keys = sorted(DISTS)\n",
    "\n",
    "    perc_ls = list()\n",
    "    mean_ls = list()\n",
    "    l_ls = list()\n",
    "    for dist_name in keys:\n",
    "        #if \"floc\" in dist_name: continue\n",
    "        num_instances = len(p_dict[SC][dist_name])\n",
    "        num_equal = np.sum([1 if p > 0.05 else 0 for p in p_dict[SC][dist_name]])\n",
    "        perc_ls.append(float(num_equal)/num_instances*100)\n",
    "        mean_ls.append(np.mean(p_dict[SC][dist_name]))\n",
    "        l_ls.append(np.mean(lkh_dict[SC][dist_name]))\n",
    "\n",
    "    sort_idx = np.argsort(perc_ls)\n",
    "    #with open(\"plots/distributions.txt\", \"a\") as fh:\n",
    "    print(\"{:>20}: {:>10s} {:>10s} {:>5s}\".format(\"name\", \"% p>0.05\", \"mean p\", \"nll\"))\n",
    "    #fh.write(\"%s\\n\" % SC)\n",
    "    #fh.write(\"{:>20}: {:>10s} {:>10s} {:>5s}\\n\".format(\"name\", \"% p>0.05\", \"mean p\", \"nll\"))\n",
    "    for idx in reversed(sort_idx):\n",
    "        print(\"{:>20}: {: 10.2f} {: 10.3f} {: 1.3f}\".format(keys[idx], perc_ls[idx], \n",
    "                                                            mean_ls[idx], l_ls[idx]))\n",
    "        #fh.write(\"{:>20}: {: 10.2f} {: 10.3f} {: 1.3f}\\n\".format(keys[idx], perc_ls[idx], \n",
    "        #                                                         mean_ls[idx], l_ls[idx]))\n",
    "    #fh.write(\"\\n\")\n",
    "    print()\n",
    "    \n",
    "    # Plot fitted distribution\n",
    "    runtimes, _, _ = load_data.get_data(scenario=SC, data_dir=data_dir, sc_dict=sc_dict, retrieve=sc_dict[SC]['use'])\n",
    "    \n",
    "    y_max_ = np.max(np.max(runtimes))\n",
    "    runtimes = (runtimes) / y_max_    \n",
    "    \n",
    "    x_axis = 10**np.arange(np.log10(0.000001), np.log10(sc_dict[SC]['cutoff']), 0.01)\n",
    "\n",
    "    cs = ['#e41a1c','#377eb8','#4daf4a','#984ea3','#ff7f00','#a65628','#f781bf','#999999']\n",
    "    colors1 = itertools.cycle(cs)\n",
    "    colors2 = itertools.cycle(cs)\n",
    "\n",
    "    num_plots = 2\n",
    "    num_runs = 10\n",
    "    plt.figure(figsize=(10, num_plots*4.5))\n",
    "    for d_idx, s_idx in enumerate(reversed(sort_idx[-num_plots:])):\n",
    "        dist_name = keys[s_idx]\n",
    "        #if \"floc\" in dist_name: continue\n",
    "\n",
    "        plt.subplot(num_plots, 1, d_idx+1)\n",
    "        min_ = 100\n",
    "        max_ = -100\n",
    "        for idx, instance in enumerate(runtimes[:num_runs]):\n",
    "            srtd = np.sort(instance)\n",
    "            yvals = np.arange(1,len(srtd)+1)/float(len(srtd))\n",
    "            min_= min(np.min(instance), min_)\n",
    "            max_= max(np.max(instance), max_)\n",
    "            plt.step(srtd, yvals, c=next(colors1))\n",
    "            #plt.hist(instance, normed=True)\n",
    "\n",
    "        for param in param_dict[SC][dist_name][:num_runs]:\n",
    "            y = dist_helper.lhood_dist(x_axis, dist_name=dist_name, param=param)\n",
    "            y = dist_helper.cdf_dist(x_axis, dist_name=dist_name, param=param)\n",
    "            plt.plot(x_axis, y, c=next(colors2))\n",
    "            \n",
    "        plt.title(\"%s; %% p: %3.3g; nll: %3.3g\" % (dist_name, perc_ls[s_idx], l_ls[s_idx]))\n",
    "        plt.xscale(\"log\")\n",
    "        plt.xlim([min_, max_])\n",
    "        #plt.ylim([-0.01, 1.01])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"plots/fitted_distributions_%s.png\" % SC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dist_name = \"invgauss_floc\"\n",
    "\n",
    "plt.figure(figsize=(5, len(SCENARIOS)*2))\n",
    "plt_idx = 0\n",
    "cs = ['#e41a1c','#377eb8','#4daf4a','#984ea3','#ff7f00','#a65628','#f781bf','#999999']\n",
    "colors1 = itertools.cycle(cs)\n",
    "\n",
    "for SC in SCENARIOS:\n",
    "    p = np.array(param_dict[SC][dist_name])\n",
    "    \n",
    "    for param_idx in (0,1):\n",
    "        plt_idx += 1\n",
    "        plt.subplot(len(SCENARIOS), 2, plt_idx)\n",
    "        if plt_idx == 1: plt.title(\"mu\")\n",
    "        if plt_idx == 2: plt.title(\"scale\")\n",
    "        if plt_idx%2 == 1: plt.ylabel(SC)\n",
    "        plt.hist(p[:, param_idx], facecolor=next(colors1), normed=True)\n",
    "            \n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"plots/%s_parameter_distribution.png\" % dist_name)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
