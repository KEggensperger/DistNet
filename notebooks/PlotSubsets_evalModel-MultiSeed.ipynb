{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot NLLH vs number of training samples\n",
    "\n",
    "This notebook creates plots which show the achieved NLLH vs the number of runtime observations per problem instance used for training the model. It expects to find pickled predictions for 10 folds and different seeds with a different number of training samples with the following filenames:\n",
    "\n",
    " * ```*_<number_of_training_samples>/<scenario_name>.floc.<dist_name>.<fold>.<seed>.<model>.pkl```\n",
    "\n",
    "`eval_model.py` automatically creates such files. \n",
    "\n",
    "To keep computation time low, this notebook uses joblib to parallelize computation across all available cores\n",
    "\n",
    "**NOTE:** The first cell contains some variables that need to be adjusted. Evaluating all scenarios might take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import scipy.stats as scst\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.externals import joblib\n",
    "import tabulate\n",
    "import time\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "## for Palatino and other serif fonts use:\n",
    "#rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=True)\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from helper import load_data, preprocess, data_source_release\n",
    "\n",
    "# 1) Set these paths\n",
    "# define output_dir such that there are <output_dir>_<numsamples> directories\n",
    "output_dir = \"../TEST\" \n",
    "save_dir = \"../results/\"\n",
    "\n",
    "distribution_ls = ['lognormal', 'invgauss', 'expon']\n",
    "distribution_hndl_ls = [scst.distributions.lognorm, scst.distributions.invgauss, scst.distributions.expon, ]\n",
    "\n",
    "# 2) Manually list available subset sizes (must match dirnames used above)\n",
    "steps = [50, 100]\n",
    "\n",
    "# 3) Select a scenario\n",
    "SCENARIO = 'clasp_factoring'\n",
    "#SCENARIO = 'lpg-zeno'\n",
    "#SCENARIO = 'yalsat_smallworlds'\n",
    "#SCENARIO = 'spear_smallworlds'\n",
    "#SCENARIO = 'saps-CVVAR'\n",
    "#SCENARIO = 'spear_qcp'\n",
    "#SCENARIO = 'yalsat_qcp'\n",
    "\n",
    "#config = \"DEFAULT\"\n",
    "LOAD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_dict = dict()\n",
    "\n",
    "if LOAD and os.path.isfile(save_dir + \"/subsets_%s_result_dict.pkl\" % SCENARIO):\n",
    "    with open(save_dir + \"/subsets_%s_result_dict.pkl\" % SCENARIO, 'rb') as fh:\n",
    "        res_dict = pickle.load(fh)\n",
    "    print(\"LOADED\")\n",
    "else:\n",
    "    dirs = glob.glob(output_dir + '_*')\n",
    "    print(dirs)\n",
    "    for step_dir in dirs:\n",
    "        if \"_results\"  in step_dir:\n",
    "            continue\n",
    "        step = int(float(step_dir.split('_')[-1]))\n",
    "        print(step)\n",
    "        for fl in os.listdir(step_dir): # + \"/%s/\" % config):\n",
    "            if SCENARIO not in fl:\n",
    "                continue\n",
    "\n",
    "            fl_path = os.path.join(step_dir, fl)\n",
    "\n",
    "            if os.path.isdir(fl_path):\n",
    "                continue\n",
    "\n",
    "            if \"txt\" in fl_path or \"png\" in fl_path:\n",
    "                continue\n",
    "            \n",
    "            if \"_result_dict.pkl\" in fl or \"_nllh_dict.pkl\" in fl:\n",
    "                continue\n",
    "                \n",
    "            if not \"pkl\" in fl:\n",
    "                continue\n",
    "\n",
    "            with open(fl_path, \"rb\") as fh:\n",
    "                pkl = pickle.load(fh)\n",
    "                train_pred = np.array(pkl[0])\n",
    "                val_pred = np.array(pkl[1])\n",
    "                add_info = pkl[2]\n",
    "                task = add_info[\"task\"]\n",
    "                model = add_info[\"model\"]\n",
    "                scenario = add_info[\"scenario\"]\n",
    "                assert scenario == SCENARIO\n",
    "                fold = add_info[\"fold\"]\n",
    "                seed = add_info[\"seed\"]\n",
    "                num_samples = add_info[\"num_train_samples\"]\n",
    "                assert step == num_samples, (fl_path, step, num_samples)\n",
    "\n",
    "            if task == 'mean':\n",
    "                continue\n",
    "\n",
    "            if model not in res_dict:\n",
    "                res_dict[model] = dict()\n",
    "                for d, hdl in zip(distribution_ls, distribution_hndl_ls):\n",
    "                    if d in model:\n",
    "                        res_dict[model]['dist'] = (d, hdl)\n",
    "            assert 'dist' in res_dict[model], (res_dict[model], model, dist, fl_path)\n",
    "\n",
    "            if step not in res_dict[model]:\n",
    "                res_dict[model][step] = dict()\n",
    "\n",
    "            if fold not in res_dict[model][step]:\n",
    "                res_dict[model][step][fold] = {\n",
    "                    \"train\": list(),\n",
    "                    \"val\": list()\n",
    "                }\n",
    "\n",
    "            res_dict[model][step][fold][\"train\"].append(train_pred)\n",
    "            res_dict[model][step][fold][\"val\"].append(val_pred)\n",
    "\n",
    "    with open(save_dir + \"/subsets_%s_result_dict.pkl\" % SCENARIO, 'wb') as fh:\n",
    "        pickle.dump(res_dict, fh)\n",
    "        print(\"dumped to \" + save_dir + \"/subsets_%s_result_dict.pkl\" % SCENARIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comput_nllh_per_inst(obs, p, dist_hdl):\n",
    "    if dist_hdl.name == \"expon\" and type(p) == np.float64: p = [p, ]\n",
    "    \n",
    "    if len(p) == 1: p = [0, p[0]]\n",
    "    elif len(p) == 2: p = [p[0], 0, p[1]]\n",
    "    else: pass\n",
    "    #print(dist_hdl, p)\n",
    "    assert p[-2] == 0\n",
    "    nllh_per_inst = dist_hdl.logpdf(obs, *p[:-2], loc=p[-2], scale=p[-1]) \n",
    "    nllh_per_inst += np.log(max(obs))              \n",
    "    nllh_per_inst = np.mean(-nllh_per_inst)\n",
    "    return nllh_per_inst\n",
    "\n",
    "def compute_nllh(obss, ps, dist_hdl):\n",
    "    nllh = list()\n",
    "    for obs, p in zip(obss, ps):\n",
    "        nllh.append(comput_nllh_per_inst(obs, p, dist_hdl))\n",
    "    return np.mean(nllh)\n",
    "\n",
    "def compute_nllh_for_all_steps(y_run, p_list, dist_hdl, n_seeds=10, steps=[1, 2, 4, 8, 16, 32, 64, 100]):\n",
    "    r_dict = dict()\n",
    "    \n",
    "    for s_idx, step in enumerate(steps):\n",
    "        nllh = [compute_nllh(y_run, p_list[s_idx][seed], dist_hdl) for seed in range(n_seeds)]\n",
    "        nllh = np.array(nllh).reshape([n_seeds, ])\n",
    "        r_dict[step] = nllh\n",
    "    return r_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if LOAD and os.path.isfile(save_dir + \"/subsets_%s_nllh_dict.pkl\" % SCENARIO):\n",
    "    with open(save_dir + \"/subsets_%s_nllh_dict.pkl\" % SCENARIO, 'rb') as fh:\n",
    "        nllh_dict = pickle.load(fh)\n",
    "    print(\"LOADED\")\n",
    "else:\n",
    "    n_seeds = 10\n",
    "\n",
    "    # 1) Load data\n",
    "    sc_dict = data_source_release.get_sc_dict()\n",
    "    data_dir = data_source_release.get_data_dir()\n",
    "\n",
    "    runtimes, features, sat_ls = load_data.\\\n",
    "        get_data(scenario=SCENARIO, data_dir=data_dir,\n",
    "                 sc_dict=sc_dict, retrieve=sc_dict[SCENARIO]['use'])\n",
    "    features = np.array(features)\n",
    "    runtimes = np.array(runtimes)\n",
    "\n",
    "    # We do not need any features\n",
    "    del features\n",
    "\n",
    "    model_list = sorted(res_dict.keys())\n",
    "    nllh_dict = dict()\n",
    "    for model in model_list:\n",
    "        nllh_dict[model] = dict()\n",
    "\n",
    "        for step in steps:\n",
    "            nllh_dict[model][step] = dict()\n",
    "\n",
    "            for fold in range(10):\n",
    "                nllh_dict[model][step][fold] = np.zeros([n_seeds, 2]) + 100\n",
    "\n",
    "    # Get CV splits\n",
    "    idx = list(range(runtimes.shape[0]))\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    fold = -1\n",
    "    for train, valid in kf.split(idx):\n",
    "        fold += 1\n",
    "\n",
    "        y_tra_run = runtimes[train]\n",
    "        y_val_run = runtimes[valid]  \n",
    "\n",
    "        y_max_ = np.max(y_tra_run.flatten())\n",
    "        y_min_ = 0\n",
    "        y_tra_run = (y_tra_run - y_min_) / y_max_\n",
    "        y_val_run = (y_val_run - y_min_) / y_max_\n",
    "\n",
    "        start = time.time()\n",
    "        with joblib.Parallel(n_jobs=-1) as para:\n",
    "            tra_nllh = para(joblib.delayed(compute_nllh_for_all_steps)(\n",
    "                y_tra_run, \n",
    "                [res_dict[model][step][fold][\"train\"] for step in steps], \n",
    "                res_dict[model]['dist'][1], n_seeds=n_seeds, steps=steps) for model in model_list)\n",
    "\n",
    "            val_nllh = para(joblib.delayed(compute_nllh_for_all_steps)(\n",
    "                y_val_run, \n",
    "                [res_dict[model][step][fold][\"val\"] for step in steps], \n",
    "                res_dict[model]['dist'][1], n_seeds=n_seeds, steps=steps) for model in model_list)\n",
    "        end = time.time()\n",
    "        print(\"Fold %d took %g sec\" % (fold, end - start))\n",
    "        # now insert results\n",
    "        for m_idx, model in enumerate(model_list):\n",
    "            for step in steps:\n",
    "                nllh_dict[model][step][fold][:, 0] = tra_nllh[m_idx][step]\n",
    "                nllh_dict[model][step][fold][:, 1] = val_nllh[m_idx][step]\n",
    "\n",
    "    with open(save_dir + \"/subsets_%s_nllh_dict.pkl\" % SCENARIO, 'wb') as fh:\n",
    "        pickle.dump(nllh_dict, fh)\n",
    "        print(\"dumped to \" + save_dir + \"/subsets_%s_nllh_dict.pkl\" % SCENARIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = sorted(list(nllh_dict))\n",
    "models = [[\n",
    "           \"expon_distfit\", \n",
    "           \"expon_distfit.rf\", \"expon_distfit.rf2\",\n",
    "           \"expon_nn\"\n",
    "          ],\n",
    "          [\n",
    "           \"invgauss_distfit\", \n",
    "           \"invgauss_distfit.rf\", \"invgauss_distfit.rf2\",\n",
    "           \"invgauss_nn\"\n",
    "          ],\n",
    "          [\n",
    "           \"lognormal_distfit\",\n",
    "           \"lognormal_distfit.rf\", \"lognormal_distfit.rf2\",\n",
    "           \"lognormal_nn\"\n",
    "          ]]\n",
    "\n",
    "style_dict = {\"expon_distfit\":         (\"EXP fitted\",  \"\", '#d95f02', 'o', 0), \n",
    "              \"expon_distfit.rf\":      (\"EXP RF\",      '#33a02c', \"\", 'x', 1),\n",
    "              \"expon_distfit.rf2\":     (\"EXP iRF\",     '#1f78b4', \"\", '+', 2),\n",
    "              \"expon_nn\":              (\"EXP DistNet\", \"\", '#252525', 'v', 3),\n",
    "              \"invgauss_distfit\":      (\"INV fitted\",  \"\", '#d95f02', 'o', 0),\n",
    "              \"invgauss_distfit.rf\":   (\"INV RF\",      '#33a02c', \"\", 'x', 1),\n",
    "              \"invgauss_distfit.rf2\":  (\"INV iRF\",     '#1f78b4', \"\", '+', 2),\n",
    "              \"invgauss_nn\":           (\"INV DistNet\", \"\", '#252525', 'v', 3),\n",
    "              \"lognormal_distfit\":     (\"LOG fitted\",  \"\", '#d95f02', 'o', 0),\n",
    "              \"lognormal_distfit.rf\":  (\"LOG RF\",      '#33a02c', \"\", 'x', 1),\n",
    "              \"lognormal_distfit.rf2\": (\"LOG iRF\",     '#1f78b4', \"\", '+', 2),\n",
    "              \"lognormal_nn\":          (\"LOG DistNet\", \"\", '#252525', 'v', 3),\n",
    "}\n",
    "\n",
    "scenario_dict = {\n",
    "    \"clasp_factoring\": r\"\\textit{Clasp}-\\textit{factoring}\",\n",
    "    \"lpg-zeno\": r\"\\textit{LPG}-\\textit{Zenotravel}\",\n",
    "    \"probsat-7sat90\": r\"\\textit{ProbSAT}-\\textit{7SAT}\",\n",
    "    \"yalsat_smallworlds\": r\"\\textit{YalSAT}-\\textit{Small}\",\n",
    "    \"yalsat_qcp-hard\": r\"\\textit{YalSAT}-\\textit{QCP-hard}\",\n",
    "    \"yalsat_qcp-backup\": r\"\\textit{YalSAT}-\\textit{QCP}\",\n",
    "    \"yalsat_bqcp\": r\"\\textit{YalSAT}-\\textit{BQCP}\",\n",
    "    \"spear_smallworlds\": r\"\\textit{Spear}-\\textit{Small}\",\n",
    "    \"spear_qcp-hard\": r\"\\textit{Spear}-\\textit{QCP-hard}\",\n",
    "    \"spear_qcp-backup\": r\"\\textit{Spear}-\\textit{QCP}\",\n",
    "    \"spear_bqcp\": r\"\\textit{Spear}-\\textit{BQCP}\",\n",
    "    \"clasp-K5\": r\"\\textit{Clasp}-\\textit{K5}\",\n",
    "    \"saps-CVVAR\": r\"\\textit{saps}-\\textit{CVVAR}\"\n",
    "}\n",
    "\n",
    "range_dict = {\n",
    "    \"clasp_factoring\": [-0.5, 0.5],\n",
    "    \"lpg-zeno\": [-1, 1],\n",
    "    \"probsat-7sat90\": [-0.6, 1],\n",
    "    \"yalsat_qcp-hard\": [-0.81, 0],\n",
    "    \"spear_smallworlds\": [-1, 3],\n",
    "    \"spear_qcp-hard\": [-1.2, 0],\n",
    "    \"clasp-K5\": [-1.5, 1],\n",
    "    \"saps-CVVAR\": [-1, 100]\n",
    "}\n",
    "\n",
    "for series in models:\n",
    "    fig = plt.figure(figsize=[10, 5])\n",
    "    a = fig.add_subplot(121)\n",
    "    b = fig.add_subplot(122, sharey=a)\n",
    "    for model in series:\n",
    "        for step in nllh_dict[model]:\n",
    "            for fold in range(10):\n",
    "                if step == 1 and fold == 0:\n",
    "                    a.scatter([step, ] * 10,\n",
    "                              nllh_dict[model][step][fold][:, 0], \n",
    "                              label=style_dict[model][0],\n",
    "                              facecolor=style_dict[model][1], \n",
    "                              edgecolor=style_dict[model][2], \n",
    "                              marker=style_dict[model][3])\n",
    "                else:\n",
    "                    a.scatter([step, ] * 10, \n",
    "                              nllh_dict[model][step][fold][:, 0], \n",
    "                              facecolor=style_dict[model][1], \n",
    "                              edgecolor=style_dict[model][2], \n",
    "                              marker=style_dict[model][3])\n",
    "                b.scatter([step, ] * 10,\n",
    "                          nllh_dict[model][step][fold][:, 1],\n",
    "                          facecolor=style_dict[model][1], \n",
    "                          edgecolor=style_dict[model][2], \n",
    "                          marker=style_dict[model][3])\n",
    "\n",
    "    a.set_title('{:s} / Train instances'.format(scenario_dict[SCENARIO]))\n",
    "    a.legend()\n",
    "    a.set_xlabel('# samples per instance')\n",
    "    a.set_ylabel('nllh')\n",
    "    yl = a.get_ylim()\n",
    "    a.set_ylim(range_dict.get(SCENARIO, [max(-1, yl[0]), min(2, yl[1])]))\n",
    "    a.set_xlim([0.9, 150])\n",
    "    a.set_xscale('log')\n",
    "    \n",
    "    b.set_title('Test instances')\n",
    "    b.set_xlabel('# samples per instance')\n",
    "    b.set_ylabel('nllh')\n",
    "    b.set_xlim([0.9, 150])\n",
    "    b.set_xscale('log')\n",
    "    \n",
    "    fig.savefig(save_dir + '%s_%s_subset.png' % (SCENARIO, model.split('_')[0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_fs = 16\n",
    "label_fs = 18\n",
    "tick_fs = 20\n",
    "title_fs = 16\n",
    "\n",
    "for series in models:\n",
    "    fig = plt.figure(figsize=[5, 5])\n",
    "    a = fig.add_subplot(111)\n",
    "    for model in series:\n",
    "        test_mean = list()\n",
    "        test_lower = list()\n",
    "        test_upper = list()\n",
    "        steps = list()\n",
    "        \n",
    "\n",
    "        for step in sorted(nllh_dict[model]):\n",
    "            tst_m = list()\n",
    "            tst_l = list()\n",
    "            tst_u = list()\n",
    "            for fold in range(10):\n",
    "                tst_m.append(np.mean(nllh_dict[model][step][fold][:, 1]))\n",
    "            \n",
    "            tst_u = np.mean(tst_m) + np.std(tst_m)\n",
    "            tst_l = np.mean(tst_m) - np.std(tst_m)\n",
    "            tst_m = np.mean(tst_m)\n",
    "\n",
    "            test_mean.append(tst_m)\n",
    "            test_lower.append(tst_l)\n",
    "            test_upper.append(tst_u)\n",
    "            steps.append(step)\n",
    "    \n",
    "        if model in (\"expon_distfit\", \"lognormal_distfit\", \"invgauss_distfit\"):\n",
    "            print(test_mean[-1])\n",
    "            steps = [steps[0], steps[-1]]\n",
    "            test_mean = [test_mean[-1], test_mean[-1]]\n",
    "            test_lower = [test_lower[-1], test_lower[-1]]\n",
    "            test_upper = [test_upper[-1], test_upper[-1]]\n",
    "    \n",
    "            a.plot(steps,\n",
    "                       test_mean, \n",
    "                       c = style_dict[model][2] if style_dict[model][1]=='' else style_dict[model][1],\n",
    "                       marker='',\n",
    "                       label=style_dict[model][0],\n",
    "                      )\n",
    "            a.fill_between(steps, test_lower, test_upper, \n",
    "                           color=style_dict[model][2] if style_dict[model][1]=='' else style_dict[model][1],\n",
    "                           alpha=0.2)\n",
    "        else:\n",
    "            a.plot(steps,\n",
    "                   test_mean, \n",
    "                   c = style_dict[model][2] if style_dict[model][1]=='' else style_dict[model][1],\n",
    "                   marker=style_dict[model][3],\n",
    "                   label=style_dict[model][0],\n",
    "                  )\n",
    "            a.fill_between(steps, test_lower, test_upper, \n",
    "                           color=style_dict[model][2] if style_dict[model][1]=='' else style_dict[model][1],\n",
    "                           alpha=0.2)\n",
    "            \n",
    "\n",
    "    a.set_title('{:s}'.format(scenario_dict[SCENARIO]), fontsize=title_fs)\n",
    "    a.legend(fontsize=legend_fs)\n",
    "    a.set_xlabel(r'\\#samples per train instance', fontsize=label_fs)\n",
    "    #a.set_ylabel(r'$\\frac{1}{|\\Pi|} \\sum_{\\pi \\in \\Pi} - \\log \\left( \\mathcal{L}_{\\mathcal{D}}(\\theta \\mid t(\\pi)_1, ..., t(\\pi)_k) \\cdot \\max_{i\\in \\{1 ... k\\}} t(\\pi)_i \\right)$')\n",
    "    a.set_ylabel(\"nllh (test)\", fontsize=label_fs)\n",
    "    yl = a.get_ylim()\n",
    "    a.set_ylim(range_dict.get(SCENARIO, [max(-1, yl[0]), min(2, yl[1])]))\n",
    "    a.set_xlim([0.9, 150])\n",
    "    a.set_xscale('log')\n",
    "    a.tick_params(axis='both', which='major', labelsize=tick_fs)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(save_dir + '/pretty_%s_%s_subset.png' % (SCENARIO, model.split('_')[0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_fs = 16\n",
    "label_fs = 25\n",
    "tick_fs = 25\n",
    "title_fs = 16\n",
    "markersize = 10\n",
    "\n",
    "new_models = [\n",
    "          #[\n",
    "          # \"expon_distfit\", \n",
    "          # \"expon_distfit.rf\", \"expon_distfit.rf2\",\n",
    "          # \"expon_nn\"\n",
    "          #],\n",
    "          #[\n",
    "          # \"invgauss_distfit\", \n",
    "          # \"invgauss_distfit.rf\", \"invgauss_distfit.rf2\",\n",
    "          # \"invgauss_nn\"\n",
    "          #],\n",
    "          [\n",
    "           \"lognormal_distfit\", #\"invgauss_distfit\",\n",
    "           \"lognormal_distfit.rf\", #\"invgauss_distfit.rf\",\n",
    "           \"lognormal_nn\", #\"invgauss_nn\"\n",
    "          ]]\n",
    "\n",
    "new_style_dict = {\"invgauss_distfit\":      (\"INV fitted\",  \"\", '#d95f02', 'o', '-', 0),\n",
    "                  \"invgauss_distfit.rf\":   (\"INV mRF\",      '#33a02c', \"\", 'x', '-', 1),\n",
    "                  #\"invgauss_distfit.rf2\":  (\"INV iRF\",     '#1f78b4', \"\", '+', 2),\n",
    "                  \"invgauss_nn\":           (\"INV DistNet\", \"\", '#252525', 'v', '-', 3),\n",
    "                  \"lognormal_distfit\":     (\"LOG fitted\",  \"\", '#d95f02', 'o', ':', 0),\n",
    "                  \"lognormal_distfit.rf\":  (\"LOG mRF\",      '#33a02c', \"\", 'x', ':', 1),\n",
    "                  #\"lognormal_distfit.rf2\": (\"LOG iRF\",     '#1f78b4', \"\", '+', 2),\n",
    "                  \"lognormal_nn\":          (\"LOG DistNet\", \"\", '#252525', 'v', ':', 3),\n",
    "}\n",
    "\n",
    "new_range_dict = {\n",
    "    \"clasp_factoring\": [-0.5, 0.5],\n",
    "    \"lpg-zeno\": [-1, 1],\n",
    "    \"probsat-7sat90\": [-0.6, 1],\n",
    "    \"yalsat_qcp-hard\": [-0.81, -0.1],\n",
    "    \"spear_smallworlds\": [-1, 3],\n",
    "    \"spear_qcp-hard\": [-1.2, 0],\n",
    "    \"clasp-K5\": [-1.5, 1],\n",
    "    \"saps-CVVAR\": [-1, 100]\n",
    "}\n",
    "\n",
    "for series in new_models:\n",
    "    fig = plt.figure(figsize=[5, 5])\n",
    "\n",
    "    a = fig.add_subplot(111)\n",
    "    for model in series:\n",
    "        test_mean = list()\n",
    "        test_lower = list()\n",
    "        test_upper = list()\n",
    "        steps = list()\n",
    "\n",
    "        for step in sorted(nllh_dict[model]):\n",
    "            if model == \"lognormal_distfit.rf\" and step == 1:\n",
    "                continue\n",
    "            tst_m = list()\n",
    "            tst_l = list()\n",
    "            tst_u = list()\n",
    "            for fold in range(10):\n",
    "                tst_m.append(np.mean(nllh_dict[model][step][fold][:, 1]))\n",
    "            #tst_l = np.percentile(tst_m, 5)\n",
    "            #tst_u = np.percentile(tst_m, 95)\n",
    "            #tst_m = np.median(tst_m)\n",
    "            \n",
    "            tst_u = np.mean(tst_m) + np.std(tst_m)\n",
    "            tst_l = np.mean(tst_m) - np.std(tst_m)\n",
    "            tst_m = np.mean(tst_m)\n",
    "\n",
    "            test_mean.append(tst_m)\n",
    "            test_lower.append(tst_l)\n",
    "            test_upper.append(tst_u)\n",
    "            steps.append(step)\n",
    "    \n",
    "        if model in (\"expon_distfit\", \"lognormal_distfit\", \"invgauss_distfit\"):\n",
    "            print(test_mean[-1])\n",
    "            steps = [steps[0], steps[-1]]\n",
    "            test_mean = [test_mean[-1], test_mean[-1]]\n",
    "            test_lower = [test_lower[-1], test_lower[-1]]\n",
    "            test_upper = [test_upper[-1], test_upper[-1]]\n",
    "    \n",
    "            l = a.plot(steps,\n",
    "                       test_mean, \n",
    "                       c = new_style_dict[model][2] if new_style_dict[model][1]=='' else new_style_dict[model][1],\n",
    "                       marker='',\n",
    "                       label=new_style_dict[model][0],\n",
    "                       linestyle=new_style_dict[model][4], linewidth=3, markersize=markersize\n",
    "                      )\n",
    "            a.fill_between(steps, test_lower, test_upper, \n",
    "                           color=new_style_dict[model][2] if new_style_dict[model][1]=='' else new_style_dict[model][1],\n",
    "                           alpha=0.2)\n",
    "        else:\n",
    "            l = a.plot(steps,\n",
    "                   test_mean, \n",
    "                   c = new_style_dict[model][2] if new_style_dict[model][1]=='' else new_style_dict[model][1],\n",
    "                   marker=new_style_dict[model][3],\n",
    "                   label=new_style_dict[model][0],\n",
    "                   linestyle=new_style_dict[model][4], linewidth=3, markersize=markersize\n",
    "                  )\n",
    "            a.fill_between(steps, test_lower, test_upper, \n",
    "                           color=new_style_dict[model][2] if new_style_dict[model][1]=='' else new_style_dict[model][1],\n",
    "                           alpha=0.2)\n",
    "            \n",
    "\n",
    "    #a.set_title('{:s}'.format(scenario_dict[SCENARIO]), fontsize=title_fs)\n",
    "    \n",
    "    #a.legend(fontsize=legend_fs)\n",
    "    \n",
    "    \n",
    "    a.set_xlabel(r'\\#samples per train instance', fontsize=label_fs)\n",
    "    #a.set_ylabel(r'$\\frac{1}{|\\Pi|} \\sum_{\\pi \\in \\Pi} - \\log \\left( \\mathcal{L}_{\\mathcal{D}}(\\theta \\mid t(\\pi)_1, ..., t(\\pi)_k) \\cdot \\max_{i\\in \\{1 ... k\\}} t(\\pi)_i \\right)$')\n",
    "    #a.set_ylabel(\"nllh (test)\", fontsize=label_fs)\n",
    "    yl = a.get_ylim()\n",
    "    a.set_ylim(new_range_dict.get(SCENARIO, [max(-1, yl[0]), min(2, yl[1])]))\n",
    "    a.set_xlim([0.9, 110])\n",
    "    a.set_xscale('log')\n",
    "    a.tick_params(axis='both', which='major', labelsize=tick_fs)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(save_dir + '/pretty_%s_%s_subset_special.png' % (SCENARIO, model.split('_')[0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
